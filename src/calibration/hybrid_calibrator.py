"""
Hybrid FFN â†’ L-BFGS Calibrator

This module combines the speed of FFN predictions with the accuracy of L-BFGS optimization.
The hybrid approach:
1. Uses fine-tuned FFN to get fast initial parameter guess (~90ms)
2. Refines with L-BFGS optimization using FFN guess as starting point (~3-10s)
3. Achieves near-optimal accuracy (target: 3-5% error) with 10-30x speedup vs pure L-BFGS

Expected Performance:
- Pure L-BFGS: 0.34% error, 106s runtime
- FFN only: 5% error, 0.09s runtime  
- Hybrid: 1-3% error, 3-10s runtime (best trade-off)

Author: Zen
Date: November 2025
"""

import numpy as np
import pickle
import sys
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

from doubleheston import DoubleHeston
from lbfgs_calibrator import DoubleHestonJumpCalibrator
from evaluate_finetuned_ffn import extract_features_single_sample

try:
    import tensorflow as tf
except ImportError:
    print("ERROR: TensorFlow not installed. Run: pip install tensorflow")
    sys.exit(1)


@dataclass
class HybridCalibrationResult:
    """Results from hybrid calibration"""
    # FFN stage
    ffn_params: np.ndarray
    ffn_time: float
    ffn_pricing_error: float
    
    # L-BFGS refinement stage
    lbfgs_params: np.ndarray
    lbfgs_time: float
    lbfgs_pricing_error: float
    lbfgs_iterations: int
    lbfgs_success: bool
    
    # Overall
    total_time: float
    improvement: float  # Reduction in error from FFN to LBFGS
    speedup_vs_cold_start: float  # Speedup vs L-BFGS from scratch


class HybridCalibrator:
    """
    Hybrid calibrator combining FFN and L-BFGS
    
    Workflow:
    1. FFN predicts initial parameters (fast, ~5% error)
    2. L-BFGS refines from FFN guess (accurate, faster convergence)
    3. Returns both FFN and refined results
    """
    
    # Parameter names in order
    PARAM_NAMES = ['v1_0', 'kappa1', 'theta1', 'sigma1', 'rho1',
                   'v2_0', 'kappa2', 'theta2', 'sigma2', 'rho2',
                   'lambda_j', 'mu_j', 'sigma_j']
    
    # Indices for log transform
    LOG_TRANSFORM_INDICES = [0, 1, 2, 3, 5, 6, 7, 8, 10, 12]
    
    def __init__(self, ffn_model_path, scalers_path):
        """
        Initialize hybrid calibrator
        
        Args:
            ffn_model_path: Path to fine-tuned FFN model
            scalers_path: Path to feature/target scalers
        """
        print("Initializing Hybrid Calibrator...")
        
        # Load FFN model
        self.ffn_model = tf.keras.models.load_model(ffn_model_path)
        print(f"âœ“ Loaded FFN model: {ffn_model_path}")
        
        # Load scalers
        with open(scalers_path, 'rb') as f:
            self.scalers = pickle.load(f)
        print(f"âœ“ Loaded scalers: {scalers_path}\n")
    
    def predict_with_ffn(self, market_prices: np.ndarray) -> Tuple[np.ndarray, float]:
        """
        Predict parameters using FFN
        
        Args:
            market_prices: Array of 15 option prices
            
        Returns:
            (predicted_params, prediction_time)
        """
        start_time = time.time()
        
        # Extract features (fixed strikes/maturities for normalization)
        fixed_strikes = np.array([90.0, 95.0, 100.0, 105.0, 110.0])
        fixed_maturities = np.array([0.25, 0.5, 1.0])
        features = np.array(extract_features_single_sample(
            market_prices, fixed_strikes, fixed_maturities, 100.0
        ))
        
        # Normalize features
        features_scaled = self.scalers['feature_scaler'].transform([features])
        
        # Predict
        pred_scaled = self.ffn_model.predict(features_scaled, verbose=0)
        
        # Inverse transform
        pred_unscaled = self.scalers['target_scaler'].inverse_transform(pred_scaled)[0]
        
        # Reverse log transform
        pred_params = pred_unscaled.copy()
        for idx in self.LOG_TRANSFORM_INDICES:
            pred_params[idx] = np.exp(pred_params[idx])
        
        elapsed = time.time() - start_time
        
        return pred_params, elapsed
    
    def compute_pricing_error(self, params: np.ndarray, market_prices: np.ndarray,
                              strikes: List[float], maturities: List[float],
                              spot: float, risk_free: float) -> float:
        """
        Compute pricing error for given parameters
        
        Args:
            params: Array of 13 parameters
            market_prices: Target market prices
            strikes: Strike prices
            maturities: Maturities
            spot: Spot price
            risk_free: Risk-free rate
            
        Returns:
            Mean percentage pricing error
        """
        pred_prices = []
        
        for T in maturities:
            for K in strikes:
                dh = DoubleHeston(
                    S0=spot, K=K, T=T, r=risk_free,
                    v01=params[0], kappa1=params[1], theta1=params[2],
                    sigma1=params[3], rho1=params[4],
                    v02=params[5], kappa2=params[6], theta2=params[7],
                    sigma2=params[8], rho2=params[9],
                    lambda_j=params[10], mu_j=params[11], sigma_j=params[12],
                    option_type='call'
                )
                price = dh.pricing(N=128)
                pred_prices.append(price)
        
        pred_prices = np.array(pred_prices)
        errors = np.abs(pred_prices - market_prices) / market_prices * 100
        return np.mean(errors)
    
    def calibrate(self, market_prices: np.ndarray, strikes: List[float],
                  maturities: List[float], spot: float = 100.0,
                  risk_free: float = 0.03, use_ffn_guess: bool = True,
                  lbfgs_maxiter: int = 200) -> HybridCalibrationResult:
        """
        Perform hybrid calibration
        
        Args:
            market_prices: Array of market option prices
            strikes: List of strike prices (absolute)
            maturities: List of maturities
            spot: Spot price
            risk_free: Risk-free rate
            use_ffn_guess: If True, use FFN prediction as initial guess
            lbfgs_maxiter: Maximum L-BFGS iterations
            
        Returns:
            HybridCalibrationResult with both FFN and L-BFGS results
        """
        total_start = time.time()
        
        # Stage 1: FFN Prediction
        print("Stage 1: FFN Prediction...")
        ffn_params, ffn_time = self.predict_with_ffn(market_prices)
        ffn_error = self.compute_pricing_error(
            ffn_params, market_prices, strikes, maturities, spot, risk_free
        )
        print(f"  âœ“ FFN: {ffn_time*1000:.1f}ms, {ffn_error:.2f}% error")
        
        # Stage 2: L-BFGS Refinement
        print("Stage 2: L-BFGS Refinement...")
        lbfgs_start = time.time()
        
        # Create market_options format for L-BFGS calibrator
        market_options = []
        for T in maturities:
            for K in strikes:
                market_options.append({
                    'strike': K,
                    'maturity': T,
                    'price': 0.0,  # Will be filled from market_prices
                    'option_type': 'call'
                })
        
        # Fill in prices (must match order: maturities outer loop, strikes inner loop)
        for i, price in enumerate(market_prices):
            market_options[i]['price'] = price
        
        # Initialize L-BFGS calibrator with market data
        lbfgs_calibrator = DoubleHestonJumpCalibrator(spot, risk_free, market_options)
        
        if use_ffn_guess:
            # Use FFN parameters as initial guess
            initial_guess = ffn_params
            print(f"  Using FFN prediction as initial guess")
        else:
            # Let L-BFGS use its own multi-start strategy
            initial_guess = None
            print(f"  Using L-BFGS cold start (multi-start)")
        
        # Run L-BFGS calibration
        lbfgs_result = lbfgs_calibrator.calibrate(
            maxiter=lbfgs_maxiter,
            multi_start=1 if use_ffn_guess else 3  # Single start with FFN guess, else multi-start
        )
        
        lbfgs_time = time.time() - lbfgs_start
        
        # Extract results
        lbfgs_params = np.array([lbfgs_result.parameters[name] for name in self.PARAM_NAMES])
        lbfgs_error = lbfgs_result.final_loss * 100  # Convert to percentage
        
        print(f"  âœ“ L-BFGS: {lbfgs_time:.1f}s, {lbfgs_error:.2f}% error")
        
        # Compute overall metrics
        total_time = time.time() - total_start
        improvement = ((ffn_error - lbfgs_error) / ffn_error) * 100
        
        # Estimate speedup (typical cold-start L-BFGS takes ~106s)
        typical_cold_start_time = 106.0
        speedup = typical_cold_start_time / total_time
        
        print(f"\n  ðŸ“Š Summary:")
        print(f"    Total time: {total_time:.1f}s")
        print(f"    Error improvement: {improvement:.1f}% ({ffn_error:.2f}% â†’ {lbfgs_error:.2f}%)")
        print(f"    Speedup vs cold-start: {speedup:.1f}x\n")
        
        return HybridCalibrationResult(
            ffn_params=ffn_params,
            ffn_time=ffn_time,
            ffn_pricing_error=ffn_error,
            lbfgs_params=lbfgs_params,
            lbfgs_time=lbfgs_time,
            lbfgs_pricing_error=lbfgs_error,
            lbfgs_iterations=lbfgs_result.iterations,
            lbfgs_success=lbfgs_result.success,
            total_time=total_time,
            improvement=improvement,
            speedup_vs_cold_start=speedup
        )


def demo():
    """Demonstration of hybrid calibration"""
    
    print("="*80)
    print("HYBRID CALIBRATOR DEMONSTRATION")
    print("="*80)
    print()
    
    # Load test data
    base_dir = Path(__file__).parent.parent
    test_data_path = base_dir / 'data' / 'lbfgs_calibrations_synthetic.pkl'
    
    with open(test_data_path, 'rb') as f:
        all_data = pickle.load(f)
    
    # Use a test sample
    test_sample = all_data[-1]  # Last sample
    
    print(f"Test Sample:")
    print(f"  Spot: {test_sample.spot:.2f}")
    print(f"  Risk-free rate: {test_sample.risk_free}")
    print(f"  Number of options: {len(test_sample.market_prices)}")
    print()
    
    # Extract strikes and maturities
    strikes = sorted(list(set([opt['strike'] for opt in test_sample.market_options])))
    maturities = sorted(list(set([opt['maturity'] for opt in test_sample.market_options])))
    
    # Initialize hybrid calibrator
    model_path = base_dir / 'models' / 'ffn_finetuned_on_lbfgs.keras'
    scalers_path = base_dir / 'data' / 'scalers.pkl'
    
    calibrator = HybridCalibrator(str(model_path), str(scalers_path))
    
    # Run hybrid calibration
    print("="*80)
    print("RUNNING HYBRID CALIBRATION")
    print("="*80)
    print()
    
    result = calibrator.calibrate(
        market_prices=test_sample.market_prices,
        strikes=strikes,
        maturities=maturities,
        spot=test_sample.spot,
        risk_free=test_sample.risk_free,
        use_ffn_guess=True,
        lbfgs_maxiter=200
    )
    
    # Print detailed results
    print("="*80)
    print("RESULTS COMPARISON")
    print("="*80)
    print()
    
    print(f"{'Method':<20} {'Time':>10} {'Error':>10} {'Notes'}")
    print("-" * 80)
    print(f"{'FFN Only':<20} {result.ffn_time*1000:>9.1f}ms {result.ffn_pricing_error:>9.2f}% {'Fast initial guess'}")
    print(f"{'Hybrid (FFN+LBFGS)':<20} {result.total_time:>9.1f}s {result.lbfgs_pricing_error:>9.2f}% {'Best accuracy/speed'}")
    print(f"{'L-BFGS Cold Start':<20} {106:>9.0f}s {'~0.34%':>10} {'Benchmark (typical)'}")
    print()
    
    print(f"Hybrid Benefits:")
    print(f"  â€¢ {result.improvement:.1f}% error reduction vs FFN-only")
    print(f"  â€¢ {result.speedup_vs_cold_start:.1f}x faster than cold-start L-BFGS")
    print(f"  â€¢ Achieves {result.lbfgs_pricing_error:.2f}% error (target: <5%)")
    
    return result


if __name__ == '__main__':
    demo()
